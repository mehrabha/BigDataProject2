# Big Data Project 2
Using MapReduce algorithm and Spark implementation.

This application takes in a collection of documents to solve the following problems:
* Compute Term Frequency â€“ Inverse Document Frequency
* Compute and sort term-term relevance

Requirements:
* Hadoop
* PySpark

Running the program:
1. Load input file into Hadoop
1. Open a terminal in the base project directory and run:  **python main.py**
1. For Spark cluster running on AWS EC2 instances:  **spark-submit main.py**
